# üöÄ Prompt d√©taill√© pour la suite du d√©veloppement

## üìã √âtat actuel du projet (17/11/2025)

### ‚úÖ Ce qui est fait et fonctionnel

#### Architecture
- **Frontend** : React + Vite + Tailwind CSS
- **Backend** : Express.js (Node.js)
- **D√©ploiement** :
  - Frontend : IONOS (h√©bergement web statique)
  - Backend : Render.com (√† d√©ployer, configur√© mais pas encore d√©ploy√©)
- **D√©ploiement automatique** : Script `npm run deploy:auto` fonctionnel

#### Fonctionnalit√©s impl√©ment√©es

1. **G√©n√©rateur d'edits en 3 √©tapes** :
   - √âtape 1 : Upload musique + intros vid√©o multiples (limite 3)
   - √âtape 2 : Brief (th√®me/style/titre + URL de r√©f√©rence + instructions)
   - √âtape 3 : Progression "live" avec suivi des √©tapes

2. **Dashboard** :
   - Liste des √©ditions cr√©√©es
   - Jobs en cours avec statut en temps r√©el
   - Rafra√Æchissement automatique toutes les 4 secondes
   - T√©l√©chargement des vid√©os (bloqu√© tant que statut != "ready")

3. **Page d'accueil** :
   - Hero section
   - Features section
   - Demo section
   - How it works
   - Pricing
   - FAQ
   - Contact form
   - Footer

4. **Backend API** :
   - `POST /api/upload` : Upload fichiers (musique/vid√©o) ‚Üí Cloudinary si configur√©
   - `POST /api/generate` : Lance un job de g√©n√©ration
   - `GET /api/status/:jobId` : Statut d√©taill√© d'un job
   - `GET /api/jobs` : Liste des jobs
   - `GET /api/edits` : Liste des edits
   - `GET /api/edits/:id` : D√©tails d'un edit
   - `DELETE /api/edits/:id` : Supprimer un edit
   - `POST /api/transcribe` : Transcription AssemblyAI
   - `POST /api/contact` : Messages de contact

5. **Int√©grations** :
   - ‚úÖ Cloudinary : Upload direct des fichiers (URLs publiques)
   - ‚ö†Ô∏è AssemblyAI : Configur√© mais n√©cessite cl√© API
   - ‚ö†Ô∏è Pexels : Placeholder si cl√© absente
   - ‚úÖ Stockage local : JSON files (edits.json, jobs.json, messages.json)

#### Configuration
- ‚úÖ Variables d'environnement configur√©es (.env, .env.production)
- ‚úÖ Scripts npm : dev, build, deploy:auto, check, diagnose
- ‚úÖ Routing React avec BrowserRouter
- ‚úÖ .htaccess pour le routing SPA sur IONOS
- ‚úÖ Logo "Auralyptix" dans la navigation

---

## üéØ Prochaines √©tapes √† impl√©menter

### Priorit√© 1 : Int√©grations r√©elles

#### 1.1 Pexels API (clips vid√©o)
**Objectif** : Remplacer les placeholders par de vrais clips Pexels

**Fichier √† modifier** : `server/index.js` (fonction `fetchClips`)

**Code actuel** (ligne ~249) :
```javascript
async function fetchClips(theme) {
  if (!pexelsEnabled) {
    return Array.from({ length: 6 }).map((_, idx) => ({
      id: `placeholder-${idx}`,
      url: `https://videos.pexels.com/video-${1000 + idx}`,
      // ...
    }));
  }
  // Code r√©el existe mais √† v√©rifier/am√©liorer
}
```

**√Ä faire** :
1. V√©rifier que la cl√© Pexels est dans `.env` et Render
2. Tester l'API Pexels avec diff√©rents th√®mes
3. G√©rer les erreurs (rate limits, pas de r√©sultats)
4. Filtrer pour ne garder que les vid√©os portrait (9:16)
5. Optimiser la s√©lection (qualit√©, dur√©e, pertinence)

**Endpoints Pexels √† utiliser** :
- `GET https://api.pexels.com/videos/search?query={theme}&orientation=portrait&size=large&per_page=10`
- Headers : `Authorization: {PEXELS_API_KEY}`

#### 1.2 AssemblyAI (transcription r√©elle)
**Objectif** : Transcrire r√©ellement les intros parl√©es

**Fichier √† modifier** : `server/index.js` (fonction `transcribeAudio`)

**Code actuel** (ligne ~163) :
```javascript
async function transcribeAudio(audioUrl) {
  if (!assemblyEnabled || isLocalUrl(audioUrl)) {
    return { text: '', words: [], note: 'Transcription simul√©e...' };
  }
  // Code r√©el existe mais √† tester
}
```

**√Ä faire** :
1. V√©rifier que la cl√© AssemblyAI est dans `.env` et Render
2. S'assurer que les URLs audio sont publiques (Cloudinary)
3. Tester avec diff√©rents formats audio
4. G√©rer les erreurs (timeout, format non support√©)
5. Extraire les timestamps des mots pour le montage

**Workflow AssemblyAI** :
1. `POST /v2/transcript` avec `audio_url`
2. Polling `GET /v2/transcript/{id}` jusqu'√† `status === 'completed'`
3. Extraire `text`, `words[]`, `utterances[]`

---

### Priorit√© 2 : Scripts Python (traitement vid√©o)

#### 2.1 Beat Detection avec Librosa
**Objectif** : D√©tecter les beats de la musique pour synchroniser les clips

**Fichier √† cr√©er** : `server/scripts/beat_detection.py`

**Fonctionnalit√©s** :
- Analyser le fichier audio (MP3, WAV)
- D√©tecter le BPM
- Extraire les positions des beats
- Retourner JSON : `{ bpm: 120, beats: [0.0, 0.5, 1.0, ...], sections: [...] }`

**D√©pendances Python** :
```bash
pip install librosa numpy
```

**Interface** :
- Input : URL du fichier audio (Cloudinary)
- Output : JSON avec beats et sections
- Appel depuis Node.js : `child_process.exec('python server/scripts/beat_detection.py {audio_url}')`

**Code de base** :
```python
import librosa
import json
import sys

audio_url = sys.argv[1]
# T√©l√©charger l'audio depuis Cloudinary
# Analyser avec librosa
# Retourner JSON
```

#### 2.2 Whisper (fallback transcription)
**Objectif** : Transcription locale si AssemblyAI √©choue

**Fichier √† cr√©er** : `server/scripts/whisper_transcribe.py`

**√Ä faire** :
- Installer Whisper (OpenAI)
- Transcrire l'audio localement
- Retourner le m√™me format que AssemblyAI

**D√©pendances** :
```bash
pip install openai-whisper
```

---

### Priorit√© 3 : Montage vid√©o avec FFmpeg

#### 3.1 Script de montage principal
**Objectif** : Cr√©er la vid√©o finale avec tous les √©l√©ments

**Fichier √† cr√©er** : `server/scripts/video_edit.py`

**Inputs** :
- Musique : URL Cloudinary
- Intro parl√©e : URL Cloudinary (avec transcription)
- Clips Pexels : Array d'URLs
- Beats : Positions des beats (JSON)
- Style : 'dynamic', 'smooth', 'aggressive', etc.
- R√©f√©rence : URL vid√©o TikTok/YouTube (optionnel)

**Processus** :
1. T√©l√©charger tous les assets
2. D√©couper l'intro selon les mots de la transcription
3. S√©lectionner les clips Pexels selon le th√®me
4. Synchroniser les clips sur les beats
5. Appliquer les transitions selon le style
6. Ajouter les effets (zoom, transitions, etc.)
7. Burner les sous-titres (si transcription disponible)
8. Mixer l'audio (musique + intro)
9. Exporter en 9:16 (1080x1920)
10. Uploader sur Cloudinary
11. Retourner l'URL finale

**D√©pendances** :
```bash
pip install ffmpeg-python pillow
```

**Commandes FFmpeg principales** :
- D√©couper : `ffmpeg -i input.mp4 -ss 00:00:10 -t 00:00:05 output.mp4`
- Concat√©ner : `ffmpeg -f concat -safe 0 -i filelist.txt -c copy output.mp4`
- Redimensionner : `ffmpeg -i input.mp4 -vf scale=1080:1920 output.mp4`
- Ajouter audio : `ffmpeg -i video.mp4 -i audio.mp3 -c:v copy -c:a aac output.mp4`
- Sous-titres : `ffmpeg -i video.mp4 -vf subtitles=subs.srt output.mp4`

**Int√©gration dans le backend** :
- Modifier `server/index.js` ‚Üí √©tape `editing`
- Appeler le script Python avec tous les param√®tres
- Attendre la fin du traitement
- R√©cup√©rer l'URL Cloudinary

---

### Priorit√© 4 : Am√©liorations UX/UI

#### 4.1 T√©l√©chargement mobile
**Objectif** : Optimiser le t√©l√©chargement sur mobile

**Fichier √† modifier** : `src/components/dashboard/VideoModal.jsx`

**√Ä faire** :
- V√©rifier que le bouton de t√©l√©chargement pointe vers l'URL Cloudinary
- Ajouter un indicateur de progression
- G√©rer les erreurs de t√©l√©chargement
- Tester sur diff√©rents appareils

#### 4.2 Am√©liorer le suivi de g√©n√©ration
**Fichier √† modifier** : `src/components/generator/GeneratingStep.jsx`

**√Ä faire** :
- Afficher un pourcentage de progression r√©el
- Afficher des messages plus d√©taill√©s par √©tape
- Ajouter des animations/effets visuels
- G√©rer les erreurs avec messages clairs

#### 4.3 Optimiser les performances
**√Ä faire** :
- Code splitting pour r√©duire la taille du bundle
- Lazy loading des composants
- Optimiser les images
- Compresser les assets

---

### Priorit√© 5 : Queue syst√®me (scalabilit√©)

#### 5.1 BullMQ + Redis
**Objectif** : G√©rer les jobs de mani√®re scalable

**Fichier √† cr√©er** : `server/queue.js`

**√Ä faire** :
- Installer BullMQ et Redis
- Cr√©er des queues pour chaque type de job
- G√©rer les priorit√©s
- Retry automatique en cas d'erreur
- Monitoring des jobs

**D√©pendances** :
```bash
npm install bullmq ioredis
```

**Configuration** :
- Redis sur Render (ou service externe)
- Queues : `video-generation`, `transcription`, `beat-detection`

---

## üîß Configuration technique d√©taill√©e

### Variables d'environnement n√©cessaires

**Backend (.env et Render)** :
```
NODE_ENV=production
PORT=10000
PUBLIC_BASE_URL=https://ton-api-render.onrender.com

# APIs
ASSEMBLYAI_API_KEY=ta_cl√©
PEXELS_API_KEY=ta_cl√©

# Cloudinary
CLOUDINARY_CLOUD_NAME=ton_cloud_name
CLOUDINARY_API_KEY=ta_cl√©
CLOUDINARY_API_SECRET=ton_secret

# Redis (pour BullMQ, optionnel)
REDIS_URL=redis://...
```

**Frontend (.env.production)** :
```
VITE_API_URL=https://ton-api-render.onrender.com
```

### Structure des fichiers

```
auto-edit-ai-39282629/
‚îú‚îÄ‚îÄ server/
‚îÇ   ‚îú‚îÄ‚îÄ index.js              # Backend Express principal
‚îÇ   ‚îú‚îÄ‚îÄ data/                  # JSON files (edits, jobs, messages)
‚îÇ   ‚îú‚îÄ‚îÄ uploads/               # Fichiers temporaires (supprim√©s apr√®s Cloudinary)
‚îÇ   ‚îî‚îÄ‚îÄ scripts/               # Scripts Python
‚îÇ       ‚îú‚îÄ‚îÄ beat_detection.py
‚îÇ       ‚îú‚îÄ‚îÄ whisper_transcribe.py
‚îÇ       ‚îî‚îÄ‚îÄ video_edit.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Generator.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Layout.jsx
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadStep.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ThemeStep.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GeneratingStep.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ VideoModal.jsx
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îî‚îÄ‚îÄ client.js          # Client API unique
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ .htaccess              # Routing SPA
‚îî‚îÄ‚îÄ dist/                       # Build de production
```

### Scripts npm disponibles

```bash
npm run dev              # Frontend uniquement
npm run dev:server       # Backend uniquement
npm run dev:full         # Frontend + Backend
npm run build            # Build production
npm run deploy:auto      # Build + Upload IONOS
npm run check            # V√©rifier la configuration
npm run diagnose         # Diagnostiquer les probl√®mes
```

---

## üìù D√©tails d'impl√©mentation par fonctionnalit√©

### 1. Int√©gration Pexels compl√®te

**Fichier** : `server/index.js` ‚Üí fonction `fetchClips`

**Code √† am√©liorer** :
```javascript
async function fetchClips(theme) {
  if (!pexelsEnabled) {
    // Fallback placeholder
    return Array.from({ length: 6 }).map((_, idx) => ({
      id: `placeholder-${idx}`,
      url: `https://videos.pexels.com/video-${1000 + idx}`,
      thumbnail: `https://images.pexels.com/photos/${1000 + idx}/pexels-photo.jpeg`,
      duration: 6 + (idx % 4),
      description: `${theme} clip ${idx + 1}`
    }));
  }

  try {
    const response = await fetch(
      `https://api.pexels.com/videos/search?query=${encodeURIComponent(
        theme || 'cinematic'
      )}&orientation=portrait&size=large&per_page=10`,
      {
        headers: {
          Authorization: process.env.PEXELS_API_KEY
        }
      }
    );

    if (!response.ok) {
      console.warn('Pexels API error, using fallback');
      return fetchClips(null); // Retry sans cl√©
    }

    const data = await response.json();
    
    // Filtrer et formater les r√©sultats
    return (data.videos || []).slice(0, 8).map((video) => {
      // Trouver le fichier vid√©o portrait de meilleure qualit√©
      const portraitFile = video.video_files?.find(
        file => file.quality === 'hd' && file.width < file.height
      ) || video.video_files?.[0];
      
      return {
        id: `pexels-${video.id}`,
        url: portraitFile?.link,
        duration: video.duration,
        thumbnail: video.image,
        description: video.user?.name || 'Pexels',
        width: portraitFile?.width,
        height: portraitFile?.height
      };
    });
  } catch (error) {
    console.error('Error fetching Pexels clips:', error);
    return fetchClips(null); // Fallback
  }
}
```

**Am√©liorations √† apporter** :
- G√©rer les rate limits (429)
- Cache des r√©sultats par th√®me
- Fallback intelligent si pas de r√©sultats
- Validation des URLs retourn√©es

---

### 2. Transcription AssemblyAI robuste

**Fichier** : `server/index.js` ‚Üí fonction `transcribeAudio`

**Code actuel √† am√©liorer** :
```javascript
async function transcribeAudio(audioUrl) {
  if (!audioUrl) {
    return { text: '', words: [], note: 'Aucune piste audio fournie' };
  }
  
  if (!assemblyEnabled || isLocalUrl(audioUrl)) {
    return {
      text: '',
      words: [],
      note: 'Transcription simul√©e (cl√© AssemblyAI absente ou URL locale)'
    };
  }

  const payload = {
    audio_url: audioUrl,
    speaker_labels: false,
    language_code: 'fr',
    punctuate: true,
    format_text: true,
    word_boost: [],
    disfluencies: true
  };

  const headers = {
    authorization: process.env.ASSEMBLYAI_API_KEY,
    'content-type': 'application/json'
  };

  // Cr√©er la transcription
  const creation = await fetch('https://api.assemblyai.com/v2/transcript', {
    method: 'POST',
    headers,
    body: JSON.stringify(payload)
  }).then((res) => res.json());

  if (creation.error) {
    throw new Error(creation.error || 'Impossible de cr√©er une transcription AssemblyAI');
  }

  // Polling jusqu'√† completion
  let attempt = 0;
  while (attempt < 60) {
    await sleep(2000);
    attempt += 1;
    const result = await fetch(
      `https://api.assemblyai.com/v2/transcript/${creation.id}`,
      { headers }
    ).then((res) => res.json());

    if (result.status === 'completed') {
      return {
        text: result.text,
        words: result.words ?? [],
        utterances: result.utterances ?? []
      };
    }

    if (result.status === 'error') {
      throw new Error(result.error || 'Transcription √©chou√©e');
    }
  }

  throw new Error('Transcription AssemblyAI trop longue (>2min)');
}
```

**Am√©liorations** :
- G√©rer les timeouts plus intelligemment
- Retry automatique en cas d'erreur temporaire
- Fallback vers Whisper si AssemblyAI √©choue
- Extraire les timestamps pr√©cis pour chaque mot

---

### 3. Script Python Beat Detection

**Fichier √† cr√©er** : `server/scripts/beat_detection.py`

**Code complet** :
```python
#!/usr/bin/env python3
import librosa
import numpy as np
import json
import sys
import requests
import tempfile
import os

def download_audio(url, temp_dir):
    """T√©l√©charge l'audio depuis Cloudinary"""
    response = requests.get(url, stream=True)
    if response.status_code != 200:
        raise Exception(f"Erreur t√©l√©chargement: {response.status_code}")
    
    ext = url.split('.')[-1].split('?')[0]
    filepath = os.path.join(temp_dir, f"audio.{ext}")
    
    with open(filepath, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    
    return filepath

def detect_beats(audio_path):
    """D√©tecte les beats avec librosa"""
    # Charger l'audio
    y, sr = librosa.load(audio_path, sr=22050)
    
    # D√©tecter le tempo et les beats
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
    beat_times = librosa.frames_to_time(beats, sr=sr)
    
    # Calculer la dur√©e
    duration = librosa.get_duration(y=y, sr=sr)
    
    # D√©tecter les sections (intro, build, drop, outro)
    sections = detect_sections(y, sr, duration)
    
    return {
        'bpm': round(float(tempo)),
        'duration': round(duration, 2),
        'beats': [round(float(t), 2) for t in beat_times],
        'sections': sections
    }

def detect_sections(y, sr, duration):
    """D√©tecte les sections de la musique"""
    # Analyse simple bas√©e sur l'√©nergie
    frame_length = 2048
    hop_length = 512
    energy = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
    
    # D√©couper en 4 sections
    section_length = duration / 4
    sections = [
        {'label': 'intro', 'start': 0, 'end': section_length},
        {'label': 'build', 'start': section_length, 'end': section_length * 2},
        {'label': 'drop', 'start': section_length * 2, 'end': section_length * 3},
        {'label': 'outro', 'start': section_length * 3, 'end': duration}
    ]
    
    return sections

def main():
    if len(sys.argv) < 2:
        print(json.dumps({'error': 'URL audio requise'}), file=sys.stderr)
        sys.exit(1)
    
    audio_url = sys.argv[1]
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # T√©l√©charger l'audio
            audio_path = download_audio(audio_url, temp_dir)
            
            # D√©tecter les beats
            result = detect_beats(audio_path)
            
            # Retourner en JSON
            print(json.dumps(result))
    except Exception as e:
        print(json.dumps({'error': str(e)}), file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
```

**Int√©gration dans Node.js** :
```javascript
async function detectBeats(audioUrl) {
  // Si pas d'URL, simulation
  if (!audioUrl) {
    return simulateBeats();
  }

  try {
    const { exec } = await import('child_process');
    const { promisify } = await import('util');
    const execAsync = promisify(exec);
    
    const { stdout, stderr } = await execAsync(
      `python server/scripts/beat_detection.py "${audioUrl}"`
    );
    
    if (stderr) {
      console.warn('Beat detection warning:', stderr);
    }
    
    return JSON.parse(stdout);
  } catch (error) {
    console.error('Beat detection failed, using simulation:', error);
    return simulateBeats();
  }
}
```

---

### 4. Script Python Montage Vid√©o

**Fichier √† cr√©er** : `server/scripts/video_edit.py`

**Structure** :
```python
#!/usr/bin/env python3
import ffmpeg
import json
import sys
import requests
import tempfile
import os
from pathlib import Path

def download_file(url, dest_path):
    """T√©l√©charge un fichier"""
    response = requests.get(url, stream=True)
    response.raise_for_status()
    with open(dest_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

def create_video_edit(config):
    """
    Cr√©e la vid√©o finale
    
    config = {
        'music_url': '...',
        'intro_url': '...',
        'clips': [...],
        'beats': [...],
        'transcription': {...},
        'style': 'dynamic',
        'output_path': '...'
    }
    """
    with tempfile.TemporaryDirectory() as temp_dir:
        # 1. T√©l√©charger tous les assets
        music_path = download_asset(config['music_url'], temp_dir, 'music.mp3')
        intro_path = download_asset(config['intro_url'], temp_dir, 'intro.mp4')
        clips_paths = [download_asset(url, temp_dir, f'clip_{i}.mp4') 
                      for i, url in enumerate(config['clips'])]
        
        # 2. D√©couper l'intro selon la transcription
        intro_segments = segment_intro(intro_path, config['transcription'])
        
        # 3. S√©lectionner et d√©couper les clips selon les beats
        clip_segments = select_clips(clips_paths, config['beats'], config['style'])
        
        # 4. Assembler la vid√©o
        final_video = assemble_video(intro_segments, clip_segments, music_path, config)
        
        # 5. Uploader sur Cloudinary
        cloudinary_url = upload_to_cloudinary(final_video)
        
        return cloudinary_url

def main():
    config_json = sys.stdin.read()
    config = json.loads(config_json)
    
    try:
        result = create_video_edit(config)
        print(json.dumps({'url': result}))
    except Exception as e:
        print(json.dumps({'error': str(e)}), file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
```

**Int√©gration dans Node.js** :
```javascript
async function createVideoEdit(jobData) {
  const config = {
    music_url: jobData.music_public_url,
    intro_url: jobData.intro_videos[0]?.url,
    clips: jobData.clips.map(c => c.url),
    beats: jobData.beats,
    transcription: jobData.transcription,
    style: jobData.style,
    theme: jobData.theme
  };

  const { exec } = await import('child_process');
  const { promisify } = await import('util');
  const execAsync = promisify(exec);
  
  const { stdout } = await execAsync(
    `python server/scripts/video_edit.py`,
    { input: JSON.stringify(config) }
  );
  
  return JSON.parse(stdout);
}
```

---

## üêõ Points d'attention et bugs connus

### Probl√®mes √† surveiller

1. **Cache navigateur** : Toujours vider le cache apr√®s d√©ploiement
2. **.htaccess** : V√©rifier qu'il est bien upload√© (fichier cach√©)
3. **Cloudinary** : V√©rifier que les URLs sont publiques avant AssemblyAI
4. **Render** : Service gratuit "s'endort" apr√®s 15 min (premier appel lent)
5. **Taille bundle** : >500KB, √† optimiser avec code splitting

### Tests √† faire

1. **Upload fichiers** : Tester avec diff√©rents formats (MP3, MP4, etc.)
2. **G√©n√©ration compl√®te** : Tester un job de bout en bout
3. **Erreurs r√©seau** : Tester avec connexion lente/interrompue
4. **Mobile** : Tester sur diff√©rents appareils
5. **Performance** : Tester avec beaucoup de jobs/edits

---

## üìö Ressources et documentation

### APIs externes
- **Pexels** : https://www.pexels.com/api/documentation/
- **AssemblyAI** : https://www.assemblyai.com/docs/
- **Cloudinary** : https://cloudinary.com/documentation

### Biblioth√®ques
- **Librosa** : https://librosa.org/doc/latest/index.html
- **FFmpeg** : https://ffmpeg.org/documentation.html
- **ffmpeg-python** : https://kkroening.github.io/ffmpeg-python/

### React Router
- **BrowserRouter** : https://reactrouter.com/en/main/router-components/browser-router
- **HashRouter** (alternative si .htaccess ne fonctionne pas) : https://reactrouter.com/en/main/router-components/hash-router

---

## üéØ Checklist pour demain

### Avant de commencer
- [ ] V√©rifier que le site fonctionne (`npm run check`)
- [ ] V√©rifier les cl√©s API (Pexels, AssemblyAI)
- [ ] Tester le d√©ploiement (`npm run deploy:auto`)

### T√¢ches prioritaires
- [ ] Int√©grer Pexels API (vraie)
- [ ] Tester AssemblyAI avec URLs Cloudinary
- [ ] Cr√©er script Python beat detection
- [ ] Cr√©er script Python montage vid√©o
- [ ] Int√©grer les scripts dans le pipeline backend

### Tests
- [ ] Tester un job complet de bout en bout
- [ ] V√©rifier que les vid√©os sont bien g√©n√©r√©es
- [ ] Tester le t√©l√©chargement
- [ ] V√©rifier les performances

---

## üí° Conseils pour la suite

1. **Commiter r√©guli√®rement** : Fais des commits Git apr√®s chaque fonctionnalit√©
2. **Tester localement** : Teste toujours en local avant de d√©ployer
3. **Logs** : Ajoute des `console.log` pour d√©bugger
4. **Gestion d'erreurs** : G√®re toujours les cas d'erreur (try/catch)
5. **Documentation** : Documente les nouvelles fonctions

---

## üîó Commandes utiles

```bash
# D√©veloppement
npm run dev:full              # Lancer front + back
npm run dev:server            # Backend uniquement
npm run dev                   # Frontend uniquement

# Production
npm run build                 # Build
npm run deploy:auto           # Build + Deploy
npm run check                 # V√©rifier config
npm run diagnose              # Diagnostiquer

# Python (quand scripts cr√©√©s)
python server/scripts/beat_detection.py "https://..."
pip install librosa numpy ffmpeg-python
```

---

**Bon courage pour la suite ! üöÄ**

